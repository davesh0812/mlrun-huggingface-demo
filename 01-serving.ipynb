{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffa0585",
   "metadata": {},
   "source": [
    "# Application Serving Pipeline\n",
    "\n",
    "This notebook demonstrate how to serve standard ML/DL models using **MLRun Serving**.\n",
    "\n",
    "Make sure you went over the basics in MLRun [**Quick Start Tutorial**](./01-mlrun-basics.html).\n",
    "\n",
    "\n",
    "MLRun serving can produce managed real-time serverless pipelines from various tasks, including MLRun models or standard model files.\n",
    "The pipelines use the Nuclio real-time serverless engine, which can be deployed anywhere.\n",
    "[Nuclio](https://nuclio.io/) is a high-performance open-source \"serverless\" framework that's focused on data, I/O, and compute-intensive workloads.\n",
    "\n",
    "\n",
    "MLRun serving supports advanced real-time data processing and model serving pipelines.<br>\n",
    "For more details and examples, see the {ref}`MLRun serving pipelines <serving>` documentation.\n",
    "\n",
    "Tutorial steps:\n",
    "- [**Create, test and build advanced model Serving Graph**](#serving-function)\n",
    "- [**Deploy the serving Function**](#deploy-serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a863f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b648af",
   "metadata": {},
   "source": [
    "<a id=\"define-project\"></a>\n",
    "## Define MLRun project and set all mlrun function\n",
    "\n",
    "You should create, load, or use (get) an **{ref}`MLRun Project <Projects>`** that holds all your functions and assets ([setup.py](./src/setup.py))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cf1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-02-15 08:47:30,829 [warning] Failed resolving version info. Ignoring and using defaults\n",
      "> 2023-02-15 08:47:33,638 [warning] Server or client version is unstable. Assuming compatible: {'server_version': '1.3.0-rc22', 'client_version': '0.0.0+unstable'}\n",
      "> 2023-02-15 08:47:49,698 [info] loaded project huggingface-demo from ./ and saved in MLRun DB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names with underscore '_' are about to be deprecated, use dashes '-' instead.Replacing underscores with dashes.\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "from src.setup import create_and_set_project\n",
    "\n",
    "project = create_and_set_project(name=\"huggingface-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673257fb",
   "metadata": {},
   "source": [
    "<a id=\"serving-function\"></a>\n",
    "## Create and test the Serving Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81336c",
   "metadata": {},
   "source": [
    "The serving function is consisted of preprocess functions that transfers the text input into a request for the serving function, and the postprocess function passes the model output into the gradio interface. \n",
    "\n",
    "See the functions in [here](./src/serving.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e4e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = mlrun.code_to_function(\n",
    "    filename=\"src/onnx_model_server.py\",\n",
    "    name=\"serving\",\n",
    "    kind=\"serving\", \n",
    "    image=\"davesh0812/mlrun:mlrun-huggingface-demo-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dede9e",
   "metadata": {},
   "source": [
    "### Defining our serving graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033cad9",
   "metadata": {},
   "source": [
    "Setting the serving graph topology with the step order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3361cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topology and get the graph object:\n",
    "graph = serving_function.set_topology(\"flow\", engine=\"async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48557ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"642pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 641.56 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 637.5587,-40 637.5587,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-.0493 40.698,-.1479 42.8263,-.2953 44.9236,-.4913 46.9815,-.7353 48.9917,-1.0266 50.9463,-1.3645 52.8377,-1.7479 54.6587,-2.1759 56.4025,-2.6472 58.0628,-3.1606 59.634,-3.7147 61.1107,-4.308 62.4882,-4.9388 63.7625,-5.6054 64.9302,-6.3059 65.9882,-7.0385 66.9343,-7.8012 67.7669,-8.5918 68.4849,-9.4082 69.0878,-10.2481 69.5758,-11.1093 69.9496,-11.9894 70.2102,-12.886 70.3595,-13.7965 70.3997,-14.7186 70.3334,-15.6497 70.1636,-16.5873 69.8937,-17.5287 69.5276,-18.4713 69.0691,-19.4127 68.5225,-20.3503 67.8923,-21.2814 67.1831,-22.2035 66.3996,-23.114 65.5464,-24.0106 64.6285,-24.8907 63.6504,-25.7519 62.617,-26.5918 61.5329,-27.4082 60.4024,-28.1988 59.2299,-28.9615 58.0197,-29.6941 56.7755,-30.3946 55.5012,-31.0612 54.2002,-31.692 52.8757,-32.2853 51.5309,-32.8394 50.1684,-33.3528 48.7908,-33.8241 47.4003,-34.2521 45.9989,-34.6355 44.5886,-34.9734 43.1708,-35.2647 41.7472,-35.5087 40.3189,-35.7047 38.8872,-35.8521 37.4531,-35.9507 36.0175,-36 34.5815,-36 33.146,-35.9507 31.7119,-35.8521 30.2801,-35.7047 28.8519,-35.5087 27.4282,-35.2647 26.0105,-34.9734 24.6001,-34.6355 23.1988,-34.2521 21.8083,-33.8241 20.4306,-33.3528 19.0681,-32.8394 17.7233,-32.2853 16.3989,-31.692 15.0979,-31.0612 13.8236,-30.3946 12.5794,-29.6941 11.3691,-28.9615 10.1967,-28.1988 9.0662,-27.4082 7.982,-26.5918 6.9486,-25.7519 5.9706,-24.8907 5.0526,-24.0106 4.1995,-23.114 3.4159,-22.2035 2.7067,-21.2814 2.0765,-20.3503 1.53,-19.4127 1.0715,-18.4713 .7053,-17.5287 .4355,-16.5873 .2657,-15.6497 .1993,-14.7186 .2395,-13.7965 .3888,-12.886 .6495,-11.9894 1.0232,-11.1093 1.5112,-10.2481 2.1141,-9.4082 2.8321,-8.5918 3.6647,-7.8012 4.6109,-7.0385 5.6689,-6.3059 6.8365,-5.6054 8.1108,-4.9388 9.4884,-4.308 10.9651,-3.7147 12.5362,-3.1606 14.1966,-2.6472 15.9404,-2.1759 17.7614,-1.7479 19.6528,-1.3645 21.6074,-1.0266 23.6176,-.7353 25.6755,-.4913 27.7728,-.2953 29.901,-.1479 32.0515,-.0493 34.2154,0 36.3837,0 38.5476,-.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- preprocess -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>preprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.9935\" cy=\"-18\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.9935\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocess</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;preprocess -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;preprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.729,-18C77.9676,-18 87.0729,-18 96.3281,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.3959,-21.5001 106.3959,-18 96.3958,-14.5001 96.3959,-21.5001\"/>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>sentiment&#45;analysis</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.5293\" cy=\"-18\" rx=\"98.2828\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.5293\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sentiment&#45;analysis</text>\n",
       "</g>\n",
       "<!-- preprocess&#45;&gt;sentiment&#45;analysis -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>preprocess&#45;&gt;sentiment&#45;analysis</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.4487,-18C239.7785,-18 248.5061,-18 257.3418,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.348,-21.5001 267.348,-18 257.348,-14.5001 257.348,-21.5001\"/>\n",
       "</g>\n",
       "<!-- postprocess -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>postprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"566.6146\" cy=\"-18\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"566.6146\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">postprocess</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;analysis&#45;&gt;postprocess -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sentiment&#45;analysis&#45;&gt;postprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M463.7157,-18C472.3627,-18 481.0331,-18 489.4706,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"489.6299,-21.5001 499.6299,-18 489.6299,-14.5001 489.6299,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f51371aef90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the serving graph:\n",
    "graph.to(handler=\"preprocess\", name=\"preprocess\")\\\n",
    "     .to(\"mlrun.frameworks.huggingface.HuggingFaceModelServer\",\n",
    "          name=\"sentiment-analysis\",\n",
    "          task=\"sentiment-analysis\",\n",
    "          model_name=\"distilbert-base-uncased\",\n",
    "          model_class=\"AutoModelForSequenceClassification\",\n",
    "          tokenizer_name=\"distilbert-base-uncased\",\n",
    "          tokenizer_class=\"AutoTokenizer\")\\\n",
    "     .to(handler=\"postprocess\", name=\"postprocess\").respond()\n",
    "\n",
    "# Plot to graph:\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f4ace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f5114d888d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# registering the serving \n",
    "project.set_function(serving_function)\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b920e8e",
   "metadata": {},
   "source": [
    "### Simulate the application pipeline locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43f3fe",
   "metadata": {},
   "source": [
    "Creating a mocking server for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ebba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-02-15 08:48:04,160 [info] model sentiment-analysis was loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The sentiment is POSITIVE', 'The prediction score is 0.5397533774375916']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server = serving_function.to_mock_server()\n",
    "server.test(path='/predict', body= \"i love flying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36600ba5",
   "metadata": {},
   "source": [
    "<a id=\"deploy-serving\"></a>\n",
    "## Deploy the serving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb967297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-02-15 08:48:04,203 [info] Starting remote function deploy\n",
      "2023-02-15 08:48:04  (info) Deploying function\n",
      "2023-02-15 08:48:04  (info) Building\n",
      "2023-02-15 08:48:04  (info) Staging files and preparing base images\n",
      "2023-02-15 08:48:04  (info) Building processor image\n",
      "2023-02-15 08:50:40  (info) Build complete\n",
      "2023-02-15 08:51:38  (info) Function deploy complete\n",
      "> 2023-02-15 08:51:38,291 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-huggingface-demo-davids-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['huggingface-demo-davids-serving-huggingface-demo-davids.default-tenant.app.cto-office.iguazio-cd1.com/']}\n"
     ]
    }
   ],
   "source": [
    "deployment = project.deploy_function(serving_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0cae67",
   "metadata": {},
   "source": [
    "### Gradio front-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a29a5f",
   "metadata": {},
   "source": [
    "Gradio is a friendly web interface that we demonstrate here how to use easily for submitting predictions to our real-time pipeline and to get the results as well!\n",
    "\n",
    "For more information, please see [gradio page](https://gradio.app/)\n",
    "\n",
    "After running this sell try to insert 'i love flying' and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c3199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://732e981d-0259-440a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://732e981d-0259-440a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.gradio_front import build_and_launch\n",
    "\n",
    "build_and_launch(url=deployment.outputs['endpoint'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
